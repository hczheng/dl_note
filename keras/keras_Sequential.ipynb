{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a2a91877-1ac6-40fb-8c9b-e40b9b315f78"
    }
   },
   "source": [
    "# Keras简单入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "013e8750-c9c6-486b-8914-fed528a0c772"
    }
   },
   "source": [
    "Keras的核心数据结构是“模型”，模型是一种组织网络层的方式。Keras中主要的模型是Sequential模型，Sequential是一系列网络层按顺序构成的栈。你也可以查看泛型模型来学习建立更复杂的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "44770ea1-c5c3-48e4-b85f-209630882c00"
    }
   },
   "outputs": [],
   "source": [
    "#Sequential模型如下：\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "#将一些网络层通过.add()堆叠起来，就构成了一个模型：\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model.add(Dense(output_dim=64, input_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "#完成模型的搭建后，我们需要使用.compile()方法来编译模型：\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "6232c2d8-cffd-4e4a-abdc-cc3cffdf977f"
    }
   },
   "source": [
    "编译模型时必须指明损失函数和优化器，如果你需要的话，也可以自己定制损失函数。Keras的一个核心理念就是简明易用同时，保证用户对Keras的绝对控制力度，用户可以根据自己的需要定制自己的模型、网络层，甚至修改源代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0cea1d9c-6f5f-41f8-92a5-789fee81c42a"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c3168a8d-69f1-4cda-a33e-7173e240fdf4"
    }
   },
   "outputs": [],
   "source": [
    "#完成模型编译后，我们在训练数据上按batch进行一定次数的迭代训练，以拟合网络\n",
    "#batch_size指的是优化算法 批梯度下降，现在用的比较多的是mini-batch gradient decent(小批的梯度下降)\n",
    "#model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)\n",
    "\n",
    "#也可以手动将一个个batch的数据送入网络中训练，这时候需要使用：\n",
    "model.train_on_batch(X_batch, Y_batch)\n",
    "\n",
    "#随后，我们可以使用一行代码对我们的模型进行评估，看看模型的指标是否满足我们的要求：\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "#或者，我们可以使用我们的模型，对新的数据进行预测：\n",
    "classes = model.predict_classes(X_test, batch_size=32)\n",
    "proba = model.predict_proba(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "600d13dd-b7f3-49bd-901b-d1970439f236"
    }
   },
   "source": [
    "# 快速开始Sequential模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b15c2586-3b1f-42de-be76-e91695572666"
    }
   },
   "source": [
    "Sequential是多个网络层的线性堆叠\n",
    "可以通过向Sequential模型传递一个layer的list来构造该模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d7b1b34c-4096-415b-8828-59f7121f3e9b"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,LSTM\n",
    "\n",
    "model = Sequential([\n",
    "Dense(32, input_dim=784),\n",
    "Activation('relu'),\n",
    "Dense(10),\n",
    "Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ddfa3877-4565-4886-ab83-655369252b0e"
    }
   },
   "outputs": [],
   "source": [
    "#也可以通过.add()方法一个个的将layer加入模型中：\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f0d11cb2-174d-4e08-9fa8-b5e1da21646a"
    }
   },
   "source": [
    "## 指定输入数据的shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7f1b3727-cd44-455d-8cd6-606103314f4b"
    }
   },
   "source": [
    "模型需要知道输入数据的shape，因此，Sequential的第一层需要接受一个关于输入数据shape的参数，后面的各个层则可以自动的推导出中间数据的shape，因此不需要为每个层都指定这个参数。有几种方法来为第一层指定输入数据的shape:\n",
    "1. 传递一个input_shape的关键字参数给第一层，input_shape是一个tuple类型的数据，其中也可以填入None，如果填入None则表示此位置可能是任何正整数。数据的batch大小不应包含在其中。\n",
    "2. 传递一个batch_input_shape的关键字参数给第一层，该参数包含数据的batch大小。该参数在指定固定大小batch时比较有用，例如在stateful RNNs中。事实上，Keras在内部会通过添加一个None将input_shape转化为batch_input_shape\n",
    "3. 有些2D层，如Dense，支持通过指定其输入维度input_dim来隐含的指定输入数据shape。一些3D的时域层支持通过参数input_dim和input_length来指定输入shape。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6cac1852-c1f0-4214-b45b-51ff4e452646"
    }
   },
   "outputs": [],
   "source": [
    "#下面的三个指定输入数据shape的方法是严格等价的：\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, batch_input_shape=(None, 784)))\n",
    "# note that batch dimension is \"None\" here,\n",
    "# so the model will be able to process batches of any size.</pre>\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d6f2886d-fca0-485b-9c7a-52e278215bf8"
    }
   },
   "outputs": [],
   "source": [
    "#下面三种方法也是严格等价的：\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 64)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, batch_input_shape=(None, 10, 64)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_length=10, input_dim=64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Merge层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "多个Sequential可经由一个Merge层合并到一个输出。Merge层的输出是一个可以被添加到新  Sequential的层对象。下面这个例子将两个Sequential合并到一起："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge\n",
    "\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "final_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](http://i.imgur.com/LcfRVlr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge层支持一些预定义的合并模式，包括：**\n",
    "- sum(defualt):逐元素相加\n",
    "- concat:张量串联，可以通过提供concat_axis的关键字参数指定按照哪个轴进行串联\n",
    "- mul：逐元素相乘\n",
    "- ave：张量平均\n",
    "- dot：张量相乘，可以通过dot_axis关键字参数来指定要消去的轴\n",
    "- cos：计算2D张量（即矩阵）中各个向量的余弦距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**这个两个分支的模型可以通过下面的代码训练:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9bae5e4b-12cc-4fb7-ac1b-eb774b1f8ecf"
    }
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "final_model.fit([input_data_1, input_data_2], targets)  # we pass one data array per model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**也可以为Merge层提供关键字参数mode，以实现任意的变换，例如：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d452f926-5d1a-4a8d-86d4-185e45836b20"
    }
   },
   "outputs": [],
   "source": [
    "merged = Merge([left_branch, right_branch], mode=lambda x: x[0] - x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 编译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在训练模型之前，我们需要通过compile来对学习过程进行配置。compile接收三个参数：\n",
    "\n",
    "- 优化器optimizer：该参数可指定为已预定义的优化器名，如rmsprop、adagrad，或一个Optimizer类的对象，详情见optimizers\n",
    "- 损失函数loss：该参数为模型试图最小化的目标函数，它可为预定义的损失函数名，如categorical_crossentropy、mse，也可以为一个损失函数。详情见objectives\n",
    "- 指标列表metrics：对分类问题，我们一般将该列表设置为metrics=['accuracy']。指标可以是一个预定义指标的名字,也可以是一个用户定制的函数.指标函数应该返回单个张量,或一个完成metric_name > metric_value映射的字典.请参考性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d39d57d1-0b1a-475b-bf90-f9f0a99a0e8a"
    }
   },
   "outputs": [],
   "source": [
    "# for a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "# for a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "# for a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='mse')\n",
    "\n",
    "# for custom metrices\n",
    "\n",
    "\n",
    "# for custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def false_rates(y_true, y_pred):\n",
    "    false_neg = ...\n",
    "    false_pos = ...\n",
    "    return {\n",
    "        'false_neg': false_neg,\n",
    "        'false_pos': false_pos,\n",
    "    }\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred, false_rates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Keras以Numpy数组作为输入数据和标签的数据类型。训练模型一般使用fit函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 5s - loss: 0.7333 - acc: 0.4900     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7180 - acc: 0.5110     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7146 - acc: 0.5110     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7017 - acc: 0.5310     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6957 - acc: 0.5370     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6824 - acc: 0.5670     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6756 - acc: 0.5890     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6727 - acc: 0.5790     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6672 - acc: 0.5890     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6551 - acc: 0.5970     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f7288cc9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a single-input model with 2 classes (binary):\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=784, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 784))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# train the model, iterating on the data in batches\n",
    "# of 32 samples\n",
    "model.fit(data, labels, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.9234 - acc: 0.1050     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.6060 - acc: 0.1270     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.4940 - acc: 0.1310     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.3536 - acc: 0.1670     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.3049 - acc: 0.1840     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.1454 - acc: 0.2420     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.0661 - acc: 0.3030     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 1.9465 - acc: 0.3210     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 1.8940 - acc: 0.3370     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 1.8513 - acc: 0.3750     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f718acedd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a multi-input model with 10 classes:\n",
    "\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(merged)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy data\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "data_1 = np.random.random((1000, 784))\n",
    "data_2 = np.random.random((1000, 784))\n",
    "\n",
    "# these are integers between 0 and 9\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "# we convert the labels to a binary matrix of size (1000, 10)\n",
    "# for use with categorical_crossentropy\n",
    "labels = to_categorical(labels, 10)\n",
    "\n",
    "# train the model\n",
    "# note that we are passing a list of Numpy arrays as training data\n",
    "# since the model has 2 inputs\n",
    "model.fit([data_1, data_2], labels, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Keras代码包的examples文件夹中，你将找到使用真实数据的示例模型：\n",
    "\n",
    "- CIFAR10 小图片分类：使用CNN和实时数据提升\n",
    "- IMDB 电影评论观点分类：使用LSTM处理成序列的词语\n",
    "- Reuters（路透社）新闻主题分类：使用多层感知器（MLP）\n",
    "- MNIST手写数字识别：使用多层感知器和CNN\n",
    "- 字符级文本生成：使用LSTM ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于多层感知器的softmax多分类：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a6127c9582f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     24\u001b[0m           \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           batch_size=16)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, input_dim=20, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, init='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          nb_epoch=20,\n",
    "          batch_size=16)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**相似MLP的另一种实现：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用于二分类的多层感知器：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
